{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1aa4d7cbbf4659a8c248bbe76bf2c20149246851"
   },
   "source": [
    "**Data_Dictionary**\n",
    "\n",
    "1. Elevation = Elevation in meters.\n",
    "2. Aspect = Aspect in degrees azimuth.\n",
    "3. Slope = Slope in degrees.\n",
    "4. Horizontal_Distance_To_Hydrology = Horizontal distance to nearest surface water features.\n",
    "5. Vertical_Distance_To_Hydrology = Vertical distance to nearest surface water features.\n",
    "6. Horizontal_Distance_To_Roadways = Horizontal distance to nearest roadway.\n",
    "7. Hillshade_9am = Hill shade index at 9am, summer solstice. Value out of 255.\n",
    "8. Hillshade_Noon = Hill shade index at noon, summer solstice. Value out of 255.\n",
    "9. Hillshade_3pm = Hill shade index at 3pm, summer solstice. Value out of 255.\n",
    "10. Horizontal_Distance_To_Fire_Point = sHorizontal distance to nearest wildfire ignition points.\n",
    "11. Wilderness_Area1 = Rawah Wilderness Area\n",
    "12. Wilderness_Area2 = Neota Wilderness Area\n",
    "13. Wilderness_Area3 = Comanche Peak Wilderness Area\n",
    "14. Wilderness_Area4 = Cache la Poudre Wilderness Area\n",
    "\n",
    "**Soil_Type1 to Soil_Type40 [Total 40 Types]**\n",
    "\n",
    "**Cover_TypeForest Cover Type designation. Integer value between 1 and 7, with the following key:**\n",
    "1. Spruce/Fir\n",
    "2.  Lodgepole Pine\n",
    "3.  Ponderosa Pine\n",
    "4.  Cottonwood/Willow\n",
    "5.  Aspen\n",
    "6.  Douglas-fir\n",
    "7.  Krummholz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's import necessary dependencies \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c248de4aa7f54b9b7eeda85eac99714e54913cce",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a4a231267092b379f0c20580291324835170bef9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "#Read data for analysis\n",
    "data=pd.read_csv('../input/covtype.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8d538112d3f282c00a7deff1c845264c1ee2626"
   },
   "source": [
    " **Explore Data Dimension and count of values without any sneak peek in Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28446ffa0321536790ffaa341aea3b3a071ca9f2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Data Dimension:')\n",
    "print('Number of Records:', data.shape[0])\n",
    "print('Number of Features:', data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2de393acf34166d57281f0106f88d318ea1a1dc7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Names of columns\n",
    "print('Feature Names')\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4c3ed1f7d237e31643ab315dc83ce9a4eb2f0d01"
   },
   "source": [
    "**Looks like we got many binary independent features. Good!**\n",
    "**Now let us understand the data type of each features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a70d60142e4e31ef198110e196aa98a83f762124",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A huge list!\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8092bb8682ac9bc9e8ea4d543d0af6c902f88963",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(y=data.dtypes ,data=data)\n",
    "plt.xlabel(\"Data Type Count\")\n",
    "plt.ylabel(\"Data types\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb32704fb4136db53a337c00c32aaf9ee58f60fb"
   },
   "source": [
    "1. **So we have complete Numeric Data, Even Better!!**\n",
    "2. **Also there doesn't seem to be any missing value. Good work at Data Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e0a239f00047a33673a2516919e495d75345425",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's check for missing values once again\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eba9bc9d7e547a885bc1cca7d7dd9f712d83a039"
   },
   "source": [
    "**We forgot to check the Data distribution for each feature. Spend some good time here. Lot's of inferences I believe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c01d0b87307dab2429a1ebb9cfc16768272c2563",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ae1de4d26af51cfa77c99589acb234a731eb737c"
   },
   "source": [
    "**#Inferences:**\n",
    "1. Few of the features looks skewed, we'll see those later.\n",
    "2. No missing Values (We say this for the third time :p)\n",
    "3. Wilderness Area and Soil Type are one hot coded.\n",
    "4. Scales are different over the whole data, hence might need to scale for some required algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f396cc5ff494b93afe8b4b6e5469357e81f06ab9"
   },
   "source": [
    "**Skewness**\n",
    ">The skewness for a normal distribution is zero, and any symmetric data should have a skewness near zero. \n",
    ">Negative values for the skewness indicate data that are skewed left and positive values for the skewness indicate data that are skewed right. \n",
    ">By skewed left, it means that the left tail is long relative to the right tail. Similarly, skewed right means that the right tail is long relative to the left tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "056d617a3263c7a1e9481135db3db5b875643961",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Skewness of the below features:')\n",
    "print(data.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a361cb8a3282500c195ed8634903181241768dd1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skew=data.skew()\n",
    "skew_df=pd.DataFrame(skew,index=None,columns=['Skewness'])\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.barplot(x=skew_df.index,y='Skewness',data=skew_df)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "545f5d1e9145dc7be70f9633bfacd943c5d2ddf4"
   },
   "source": [
    "**#Inferences:**\n",
    "> Some of the Variables are heavily skewed hence need to be corrected or transformed  on a later stage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e63404074cf4bfa7de169585c33a8acb69638f5"
   },
   "source": [
    "**How about the class balance? We'll see**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "27e817978b808cc8825e3ab69199028998bb5a96",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_dist=data.groupby('Cover_Type').size()\n",
    "class_label=pd.DataFrame(class_dist,columns=['Size'])\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x=class_label.index,y='Size',data=class_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "27ae50bd9ce75e3b6d1ad7ca123c6ff05363e03d"
   },
   "source": [
    "> But I'm interested in percentwise distribution of each class. Let's check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27e817978b808cc8825e3ab69199028998bb5a96",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,number in enumerate(class_dist):\n",
    "    percent=(number/class_dist.sum())*100\n",
    "    print('Cover_Type',class_dist.index[i])\n",
    "    print('%.2f'% percent,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d6aec286d5b147df0b177191c40f54eebec16d43"
   },
   "source": [
    "**#Inferences:**\n",
    "1.  Cover_Type 1 and 2 i.e **Spruce/Fir** and **Lodgepole Pine** seems to dominate the area. \n",
    "2.  Also the Cover_Type 4 i.e **Cottonwood/Willow** is minimal compare to the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d99b3e456576d1992800d6d65e878a45ee81ef3e"
   },
   "source": [
    "**Oh common let us check the data atleast, enough with size and dimension**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb3da20c95716478a1e6f641a6daca53eda86da5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d0ec24ba66556a084987646695152c7bd74dcce"
   },
   "source": [
    ">Nice! Now, Let's convert the whole data into few Mini datasets. I'll make use of it in plots\n",
    "* cont_data - Data without binary features i.e continuous features\n",
    "* binary_Data - Data having all binary features [Wilderness Areas + Soil Types]\n",
    "* wilderness_Data - Binary Wilderness Areas\n",
    "* Soil_Data - Binary Soil Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d30d7fa96858100cb279ddb7a022c07e1304b5d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_data=data.loc[:,'Elevation':'Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "binary_data=data.loc[:,'Wilderness_Area1':'Soil_Type40']\n",
    "\n",
    "Wilderness_data=data.loc[:,'Wilderness_Area1': 'Wilderness_Area4']\n",
    "\n",
    "Soil_data=data.loc[:,'Soil_Type1':'Soil_Type40']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0dba7292e6b469286816d1aeff90ceb455c3178"
   },
   "source": [
    "\n",
    "**I want to see the number of  values counts within each features, mainly for the Binary types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dbde0796f7f7f0bf5b6ca5faa22ca109cd352d08",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Iterate via columns of data having only binary features\n",
    "for col in binary_data:\n",
    "    count=binary_data[col].value_counts()\n",
    "    print(col,count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "de68aa24b94a5499d970dc111b1a15e167a325f2"
   },
   "source": [
    "**#Inferences:**\n",
    "> **This tells me lots of valuable insights. Mostly regarding the soil types. Wanna know? Ok, let me not hide it from you**.\n",
    "* It's Just that, there are some of the Soil types which consists of very few counts.  \n",
    "* Statistically speaking, for half a million records, balance number per soil type (total 40 in number) is 581012/40 = 14.5k\n",
    "* Whereas, here we see a different figure. I know that data need not be balanced all the times. But may be we can get rid of really small size features. Isn't it?\n",
    "* Let me list down those along with there size. I'm displaying the Soil type having less than 1000 occurence size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b576e27da307517838ed6741c8508570f71ff740",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Soil Type',' Occurence_count')\n",
    "for col in binary_data:\n",
    "    count=binary_data[col].value_counts()[1] #considering all one's among 1 and 0's in each soil type\n",
    "    if count < 1000:\n",
    "        print(col,count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c8b005f8919c5b7be1b54411360dfe0fbd91860"
   },
   "source": [
    "* I know this will make more sense in a visual such as bar graph right? I'm excited to see it too. But let's infer more from the numbers as of now. \n",
    "* We'll do plottings once we start with Bivariate and Multivariate analysis. \n",
    "* We'll see if we need to really drop the above soil types. \n",
    "* We can only confirm on it if it is not aligned (give any relation) to our target variable i.e Cover_Type. So, please wait, do not conclude. Climax is yet to come :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "671a69114a215e0e1bde23325d7b6bf37ada2b46"
   },
   "source": [
    "**Let's get started with plots based EDA (Exploratory Data Analysis) **\n",
    "*  Fun begins here, am I right?\n",
    "* Data Distribution of features via Histograms. Although I love box plots more than histograms, we'll use boxplot to check distribution with respect to categorical variable. In our case that is Cover_Type, having 7 different category of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cef9801666851dc8a3e79c88e5916cd058f9d2a0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_num = data.select_dtypes([np.int, np.float]) #If you need to select only numeric features. \n",
    "#Here we already have all numeric Data.\n",
    "\n",
    "for i, col in enumerate(cont_data.columns):\n",
    "    plt.figure(i)\n",
    "    sns.distplot(cont_data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fa9c8b73a7e8053d0bc19d9909359ef008e5f5b"
   },
   "source": [
    "* > The above plots more or less tells us about the skewness that we saw earlier. Let's dig down into Bivariate and Multivariate Analysis\n",
    "* > Let's check for distribution with respect to our target. This is where magic happens!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60865c704c31262f0a1919984a10c371c0bd2508"
   },
   "source": [
    "* > Here, First i want to check the shape of continous features with respect to the target class. Hence I'll use the continuous_data (cont_data) and plot a boxplot against target. \n",
    "* > You can also look at violinplot here, It's visually appealing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28b0a53df98b09d9ff5fe7427d042db3030544ae",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "data['Cover_Type']=data['Cover_Type'].astype('category') #To convert target class into category\n",
    "\n",
    "for i, col in enumerate(cont_data.columns):\n",
    "    plt.figure(i,figsize=(8,4))\n",
    "    sns.boxplot(x=data['Cover_Type'], y=col, data=data, palette=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b5527d099d4e9b436a7224bd7cfbfca04b048697"
   },
   "source": [
    "*  Plots looks cool right? What's Even more cool you know?\n",
    "*  The insights. Let's figure out very general insights\n",
    "*  There are couple of features which shows not much of variance with respect to classes\n",
    "*  And features such as 'Elevation', 'slope' and 'horizontal distance to road_ways does a good job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "611cc005d1ba2665ccc13df4bf4d53c68357742c"
   },
   "source": [
    "> Let's do something similar for our binary features. This time we'll use countplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "026c5430f1e2d76da2e53b91949e81303d7fa616",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, col in enumerate(binary_data.columns):\n",
    "    plt.figure(i,figsize=(6,4))\n",
    "    sns.countplot(x=col, hue=data['Cover_Type'] ,data=data, palette=\"rainbow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4af3dd3eb77700491615e664bde069328259b87f"
   },
   "source": [
    "* > So the plot does justice to the distribution which each class but I want to have a single feature having Soil_Type corresponding to each row. \n",
    "* > Let's see if I can do it.  This will help me to visualize it better, instead of counting 0's and 1's in each one hot coded Soil types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8bf550289be6b393c68a8dd5006021c629490e0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#If someone can help me with function to reverse one hot coding, please let me know in comment. I know this is not the robust way.\n",
    "def rev_code(row):\n",
    "    for c in Soil_data.columns:\n",
    "        if row[c]==1:\n",
    "            return c  \n",
    "\n",
    "data['Soil_Type']=Soil_data.apply(rev_code, axis=1) #Time consuming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b13373d2ba5ec6baaaa57c54b9afe80e32e19a52"
   },
   "source": [
    "> I'll do the same for Wilderness Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae266ab5a58001b165670e2477e5196362ed261a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def rev_code(row):\n",
    "    for c in Wilderness_data.columns:\n",
    "        if row[c]==1:\n",
    "            return c  \n",
    "\n",
    "data['Wilderness_Type']=Wilderness_data.apply(rev_code, axis=1) #Time consuming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c4d1b1505cd77f8288a226f593f650529912387"
   },
   "source": [
    "> Yup! It's done. Looks like we have a desired single Soil_Type and Wilderness_Type feature. Let's now use count plot against our Target Cover_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "254bf19bacf98f657ee426e20274b3eed84d20d0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.countplot(x='Wilderness_Type', hue='Cover_Type',data=data, palette=\"rainbow\")\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0f36598f67a4eef65616196682df3d2dfe4097f5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.countplot(x='Soil_Type', hue='Cover_Type',data=data, palette=\"rainbow\")\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92fe920a395066bddd09e1a32321c23519f788cb"
   },
   "source": [
    "* >Above two plots tells  us the count of trees in each class considering Wilderness and Soil Type.\n",
    "* >Soil_Type plot is not very clear since it's  too vast. So let's go by the number. We'll see how many and what type of Cover_Type we have under each soil Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b1a94e34616decd479da57562c1160e201148952",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soil_counts = []\n",
    "for num in range(1,41):\n",
    "    col = ('Soil_Type' + str(num))\n",
    "    this_soil = data[col].groupby(data['Cover_Type'])\n",
    "    totals = []\n",
    "    for value in this_soil.sum():\n",
    "        totals.append(value)\n",
    "    total_sum = sum(totals)\n",
    "    soil_counts.append(total_sum)\n",
    "    print(\"Total Trees in Soil Type {0}: {1}\".format(num, total_sum))\n",
    "    percentages = [ (total*100 / total_sum) for total in totals]\n",
    "    print(\"{0}\\n\".format(percentages))\n",
    "print(\"Number of trees in each soil type:\\n{0}\".format(soil_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f2218fa8afa6140b2dd3118eefb05b3e40d1c41e"
   },
   "source": [
    "**Did we check the co-relation??**\n",
    " * > No we didn't. This is something that I usually check first. No, problem. it's never too late.\n",
    " * > Let's better vizualise it via heatmap. All in one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be8c8b4eb171c74fca69a7bf1e0ef0682c246a08",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(cont_data.corr(),cmap='magma',linecolor='white',linewidths=1,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9bbc24881ed9b3afc6b273f4551e3f32241d7d10"
   },
   "source": [
    "* >Couple of features are have a good amount of co-relation. Guess which one? I'll tell you.\n",
    "* >  Hillshade_9am ~ Hillshade_3pm and Aspect ~ Hillshade_3pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7d7e6149ea19d2b34eebd61ec735151d71d392f4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = sns.PairGrid(cont_data)\n",
    "g.map(plt.scatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "052943bc469edeef5ffe603e375773668d6130e8"
   },
   "source": [
    "* > This gives us the relation and its shape with respect to other features. Various inferences can be drwan out.\n",
    "* > Pairgrid plot is just awesome. And it's even more awesome when it's combined with KDE clusters. \n",
    "* > But for considerably heavy data, its time consuming. Be aware before running the below plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5519a2c95757982d4b9cdfeec6dd3605cb8c07a0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# g = sns.PairGrid(cont_data)\n",
    "# g.map_diag(plt.hist)\n",
    "# g.map_upper(sns.kdeplot)\n",
    "# g.map_lower(sns.kdeplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b54c06bd227e324931d6d02bef47cfafc1bf6fc"
   },
   "source": [
    "* > There's lot of scope for Data Viz. as far this dataset is concerned. My objective was a surface walkthrough the dataset. I would roll out new versions on this part by part. \n",
    "* >Let's now wind it up by Data Modelling. Another Excitement, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fc23b55e7317cdda4dac2c26de0158b379d9e0a6"
   },
   "source": [
    "**Data Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be8305ee10ee4b5facf6abfbaacafe6476948ca3"
   },
   "source": [
    "* X = Input or independent variables\n",
    "* y=  Target variable ('Cover_Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6a2b6699b55b41042e877d4363e3175cdb3c7ed4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=data.loc[:,'Elevation':'Soil_Type40']\n",
    "y=data['Cover_Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2fbfa3b573fc3aa58c9a6ba9fb647a549a08fa6a"
   },
   "source": [
    ">Let us take a step to remove the features with low Std deviation as demonstrated earlier. \n",
    ">Also I'll remove one of the co-related variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e4e088c48c0bf52ce1f45a8494d47c565805044",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Features to be removed before the model\n",
    "rem=['Hillshade_3pm','Soil_Type7','Soil_Type8','Soil_Type14','Soil_Type15',\n",
    "     'Soil_Type21','Soil_Type25','Soil_Type28','Soil_Type36','Soil_Type37']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d8c007c9976926b1f1226cac6a932bb561e909f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove the unwanted features\n",
    "X.drop(rem, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "543c845b245fb48bdaea6f0e1cb5eec10cae07ba",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting the data into  train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58215d4477a96dbb0386d1097e73afc78f67d733"
   },
   "source": [
    "* ** I have tried various Classification algorithms out of which KNN served the best.**\n",
    "* ** Algorithms such as RandomForest and DecisionTree are doing a decent job here. So please explore.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d4c634bad923190233c65cd54dd71cad05ae25b9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Setup arrays to store training and test accuracies\n",
    "neighbors = np.arange(1,7)\n",
    "train_accuracy =np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "for i,k in enumerate(neighbors):\n",
    "    #Setup a knn classifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    #Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the test set\n",
    "    test_accuracy[i] = knn.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe44b85c5df770a14ccbb0b90f72da658dac0c24"
   },
   "source": [
    "> Let's visualize the change in accuracies with respect to train and test data at different neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "1e3395d10408f7351b806fdca7131470ebed120f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title('k-NN Varying number of neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label='Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label='Training accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9e391ba0dfe0c5811a00a339a040f036487c1213"
   },
   "source": [
    "> Neighbor value = 5 yeilds the best result. Let's go by that for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a5a060a18848c522ca5609a42552e5aea100ede8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setup a knn classifier with k neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5) #Using Eucledian distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffaad4771a1056b28705a14705c1c53879839715",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7e81e2fe6bb2b7565605a97e07312a6b152dca7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get accuracy. Note: In case of classification algorithms score method represents accuracy.\n",
    "Accuracy=knn.score(X_test,y_test)\n",
    "print('KNN Accuracy:',Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94a92a0773d9341776b0ae37ce32f549e4e09ce4"
   },
   "source": [
    "**Not bad. KNN works great here. Lazy learner is doing a good work at differentiating a CoverType. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "49b6572a1c145fb30763e88ac0433c5aa613b2d6"
   },
   "source": [
    "**I'll put the accuracies obtained by various other classification techniques. Try to enhance it more via Cross Validation may be.**\n",
    "**Let me know in comment if you manage to raise your accuracies. **\n",
    "> **I'm gonna do it too. Those are my next steps, such as CV, more insights, Feature engineering etc. I'll roll out updates part by part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "22a7d409b3d1326f52c288ed54af273d9c7bacef",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import zscore\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "319f975de7d9ae014f56bf271754995872a237c2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "MLA = []\n",
    "Z = [LinearSVC() , DecisionTreeClassifier() , LogisticRegression() , GaussianNB() ,RandomForestClassifier() , \n",
    "     GradientBoostingClassifier()]\n",
    "X = [\"LinearSVC\" , \"DecisionTreeClassifier\" , \"LogisticRegression\" , \"GaussianNB\" ,\"RandomForestClassifier\" , \n",
    "     \"GradientBoostingClassifier\"]\n",
    "\n",
    "for i in range(0,len(Z)):\n",
    "    model = Z[i]\n",
    "    model.fit( X_train , y_train )\n",
    "    pred = model.predict(X_test)\n",
    "    MLA.append(accuracy_score(pred , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "568a816c887c1ffad49f8db7743c8d2c7c59fb5a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = { \"Algorithm\" : X, \"Accuracy\" : MLA }\n",
    "\n",
    "dfm = pd.DataFrame(d)\n",
    "dfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5ab39c24eef7bff7345251d78ea1395cf6ad21c"
   },
   "source": [
    "*  **Try to surpass these accuracies. **\n",
    "*  **My objective was to 'Get to know' the Forest Cover Type Dataset for which I tried to articulate it step by step.**\n",
    "*  **If you liked it, please let me know with a upvote, It serves a Motivation. Good Luck and Thank you for spending your time here! :)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
